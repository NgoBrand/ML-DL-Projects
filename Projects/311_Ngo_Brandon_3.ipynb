{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b494fa9-0757-49a7-878f-f8ff1c42c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Pandas for data handling\n",
    "import pandas # https://pandas.pydata.org/\n",
    "# from pandas.plotting import scatter_matrix\n",
    "\n",
    "# pretty tables\n",
    "from IPython.display import display\n",
    "\n",
    "# NumPy for numerical computing\n",
    "import numpy # https://numpy.org/\n",
    "\n",
    "# MatPlotLib+Seaborn for visualization\n",
    "import matplotlib.pyplot as pl  # https://matplotlib.org/\n",
    "import seaborn as sns\n",
    "\n",
    "# assessment\n",
    "from sklearn import model_selection # for model comparisons\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# algorithms\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# data preprocessing / feature selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# combining\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f8f5f3-34c6-4615-ab7c-881aa5a77dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file ...\n",
      "done \n",
      "\n",
      "Removing rows with missing data ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading data from file ...')  # Now let's load the data\n",
    "dataset = pandas.read_csv('winequality-white.csv') # default is header=infer, change if column names are not in first row\n",
    "print('done \\n')\n",
    "\n",
    "print('Removing rows with missing data ...')  # Make things simple\n",
    "dataset = dataset.dropna()  # default is to drop any row that contains at least one missing value\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5a2194-cda4-4008-9960-4e3b19accf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of problem variables X and Y...\n",
      "done \n",
      "\n",
      "Partitioning data into parts: formative (for development) and summative (for testing) ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's set up a problem: Can we predict 'quality' using these three features: 'fixed acidity', 'alcohol', 'pH' ?\n",
    "\n",
    "print('Reading list of problem variables X and Y...')\n",
    "X_name = [ 'fixed acidity', 'alcohol', 'pH' ] # columns to focus on as predictors\n",
    "X = dataset[X_name]   # only keep these columns as features\n",
    "y_name = 'quality'     # column to focus on as target\n",
    "y = dataset[y_name]   # only keep this column as label \n",
    "print('done \\n')\n",
    "\n",
    "# Split-out test dataset\n",
    "\n",
    "# We reset the random number seed before each run to ensure that the evaluation of each algorithm is performed using exactly the same data splits. It ensures the results are directly comparable.\n",
    "seed = 27\n",
    "\n",
    "# Train, test split\n",
    "print('Partitioning data into parts: formative (for development) and summative (for testing) ...')\n",
    "test_size = 0.20   # means 20 percent\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1ecebc6-4bd5-4ffe-b9df-9e8ae4cdb580",
   "metadata": {},
   "source": [
    "1. Train and tune the MLPClassifier (via cross-validation) using at least three different\n",
    "combinations of architecture choices (e.g., number of layers, # of neurons per\n",
    "layer, activation function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576a22ff-0752-4848-ae98-613812571a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of algorithms to train ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Will take the two models that have been chosen to be tested\n",
    "print('Reading list of algorithms to train ...')\n",
    "models = []\n",
    "models.append(( 'MLP', MLPClassifier(hidden_layer_sizes=(100,), \n",
    "                                     activation='relu',  \n",
    "                                     ) )) #Basic default for all\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb63b68-0d77-4948-bd45-784c3efedc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of scoring methods to use during model development ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Reading list of scoring methods to use during model development ...')\n",
    "scoring = 'accuracy'\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14fb854d-72e9-4486-a331-d44a11089493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ++ NOW WORKING ON ALGORITHM MLP ++\n",
      "Splitting data into 5 folds\n",
      "Training model on each split\n",
      "algorithm MLP accuracy results: mean = 0.477541 (std = 0.009491)\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now it is time to develop (train and validate) the models on the formative data set there will be two models\n",
    "\n",
    "k4folds = 5   # This will split our formative dataset into five parts;\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:   # Select each model in turn\n",
    "    print(\" ++ NOW WORKING ON ALGORITHM %s ++\" % name)\n",
    "    print(\"Splitting data into %s folds\" % k4folds)\n",
    "    kfold = model_selection.KFold(n_splits=k4folds, random_state=seed, shuffle=True)   # fit the model using four parts at a time and then validate it on the oher part that was set aside; and repeat five times.\n",
    "    print(\"Training model on each split\")\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"algorithm %s %s results: mean = %f (std = %f)\" % (name, scoring, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "print('done \\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7781716d-2f06-426d-a594-16bc19312081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found on development set:\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100, 100)}\n",
      "Grid scores on development set:\n",
      "0.479 (+/-0.031) for {'activation': 'identity', 'hidden_layer_sizes': (100,)}\n",
      "0.478 (+/-0.029) for {'activation': 'identity', 'hidden_layer_sizes': (100, 100)}\n",
      "0.474 (+/-0.011) for {'activation': 'identity', 'hidden_layer_sizes': (100, 50)}\n",
      "0.465 (+/-0.027) for {'activation': 'identity', 'hidden_layer_sizes': (50, 50)}\n",
      "0.488 (+/-0.027) for {'activation': 'logistic', 'hidden_layer_sizes': (100,)}\n",
      "0.482 (+/-0.022) for {'activation': 'logistic', 'hidden_layer_sizes': (100, 100)}\n",
      "0.490 (+/-0.025) for {'activation': 'logistic', 'hidden_layer_sizes': (100, 50)}\n",
      "0.483 (+/-0.023) for {'activation': 'logistic', 'hidden_layer_sizes': (50, 50)}\n",
      "0.479 (+/-0.022) for {'activation': 'tanh', 'hidden_layer_sizes': (100,)}\n",
      "0.490 (+/-0.019) for {'activation': 'tanh', 'hidden_layer_sizes': (100, 100)}\n",
      "0.485 (+/-0.012) for {'activation': 'tanh', 'hidden_layer_sizes': (100, 50)}\n",
      "0.477 (+/-0.030) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50)}\n",
      "0.474 (+/-0.037) for {'activation': 'relu', 'hidden_layer_sizes': (100,)}\n",
      "0.465 (+/-0.024) for {'activation': 'relu', 'hidden_layer_sizes': (100, 100)}\n",
      "0.480 (+/-0.029) for {'activation': 'relu', 'hidden_layer_sizes': (100, 50)}\n",
      "0.468 (+/-0.027) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50)}\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tuning the MLP model\n",
    "selected_model = MLPClassifier()\n",
    "hyperparameters = {'hidden_layer_sizes':[(100,), (100, 100), (100, 50), (50, 50)], 'activation':['identity', 'logistic', 'tanh', 'relu'] }\n",
    "\n",
    "\n",
    "\n",
    "print(\"Now tuning hyperparameters...\")\n",
    "mlp = GridSearchCV(selected_model, hyperparameters, cv=5, scoring=scoring)\n",
    "\n",
    "   \n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters found on development set:\")\n",
    "print(mlp.best_params_)\n",
    "print(\"Grid scores on development set:\")\n",
    "means = mlp.cv_results_['mean_test_score']\n",
    "stds = mlp.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, mlp.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print('done \\n')\n",
    "\n",
    "tuned_model = mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bc74c08-3b00-4ee0-bd06-9fd903980161",
   "metadata": {},
   "source": [
    "Best hyperparameters found on development set:\n",
    "{'activation': 'tanh', 'hidden_layer_sizes': (100, 100)}\n",
    "0.490 (+/-0.019) for {'activation': 'tanh', 'hidden_layer_sizes': (100, 100)}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ca8f898-b656-4755-b93d-59b7a661e098",
   "metadata": {},
   "source": [
    "2. Study (via cross-validation) and describe the performance impact of varying at\n",
    "least three different combinations of optimizer parameter values (e.g., solver,\n",
    "epoch, learning rate) for one of the architectures in Step 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7dbe62-52b2-4a55-9546-9195fc9ff736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of algorithms to train ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Reading list of algorithms to train ...')\n",
    "models = []\n",
    "models.append(( 'lbfgs100', MLPClassifier(hidden_layer_sizes=(100, 100), \n",
    "                                     activation='tanh',\n",
    "                                     solver='lbfgs',\n",
    "                                     max_iter=100,\n",
    "                                     ) )) \n",
    "models.append(( 'sgb100', MLPClassifier(hidden_layer_sizes=(100, 100), \n",
    "                                     activation='tanh',\n",
    "                                     solver='sgd',\n",
    "                                     max_iter=100,\n",
    "                                     ) )) \n",
    "models.append(( 'lbfgs50', MLPClassifier(hidden_layer_sizes=(100, 100), \n",
    "                                     activation='tanh',\n",
    "                                     solver='lbfgs',\n",
    "                                     max_iter=50,\n",
    "                                     ) )) \n",
    "models.append(( 'sgb50', MLPClassifier(hidden_layer_sizes=(100, 100), \n",
    "                                     activation='tanh',\n",
    "                                     solver='sgb',\n",
    "                                     max_iter=50,\n",
    "                                     ) )) \n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2df9d92-7dc1-4b58-abc0-6f10c2da23c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of scoring methods to use during model development ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Reading list of scoring methods to use during model development ...')\n",
    "scoring = 'accuracy'\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c79cdb5e-5347-4068-8ddc-9f02857184d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ++ NOW WORKING ON ALGORITHM lbfgs100 ++\n",
      "Splitting data into 5 folds\n",
      "Training model on each split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm lbfgs100 accuracy results: mean = 0.490048 (std = 0.007421)\n",
      " ++ NOW WORKING ON ALGORITHM sgb100 ++\n",
      "Splitting data into 5 folds\n",
      "Training model on each split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm sgb100 accuracy results: mean = 0.483158 (std = 0.012986)\n",
      " ++ NOW WORKING ON ALGORITHM lbfgs50 ++\n",
      "Splitting data into 5 folds\n",
      "Training model on each split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm lbfgs50 accuracy results: mean = 0.488265 (std = 0.011765)\n",
      " ++ NOW WORKING ON ALGORITHM sgb50 ++\n",
      "Splitting data into 5 folds\n",
      "Training model on each split\n",
      "algorithm sgb50 accuracy results: mean = nan (std = nan)\n",
      "done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 501, in _validate_hyperparameters\n",
      "    raise ValueError(\n",
      "ValueError: The solver sgb is not supported.  Expected one of: sgd, adam, lbfgs\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# Now it is time to develop (train and validate) the models on the formative data set there will be two models\n",
    "\n",
    "k4folds = 5   # This will split our formative dataset into five parts;\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:   # Select each model in turn\n",
    "    print(\" ++ NOW WORKING ON ALGORITHM %s ++\" % name)\n",
    "    print(\"Splitting data into %s folds\" % k4folds)\n",
    "    kfold = model_selection.KFold(n_splits=k4folds, random_state=seed, shuffle=True)   # fit the model using four parts at a time and then validate it on the oher part that was set aside; and repeat five times.\n",
    "    print(\"Training model on each split\")\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"algorithm %s %s results: mean = %f (std = %f)\" % (name, scoring, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "print('done \\n') "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b935037-3917-4766-a968-3d5aeea2f066",
   "metadata": {},
   "source": [
    "best: algorithm lbfgs100 accuracy results: mean = 0.490048 (std = 0.007421). Sorry bout the warnings, i couldnt figure out how to do the warning ignore function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b881ecc0-3dcf-47b2-8da1-916310816d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ++++ Detailed classification report for the selected model ++++ \n",
      "Algorithm MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 100), max_iter=100,\n",
      "              solver='lbfgs') \n",
      "This model was trained and tuned on the development set using CV.\n",
      "The following results are computed on the separate test set:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.45      0.61      0.52       264\n",
      "           6       0.54      0.60      0.57       471\n",
      "           7       0.49      0.30      0.37       175\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51       980\n",
      "   macro avg       0.21      0.22      0.21       980\n",
      "weighted avg       0.47      0.51      0.48       980\n",
      "\n",
      "\n",
      "\n",
      "done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model1 = MLPClassifier(hidden_layer_sizes=(100, 100), \n",
    "                       activation='tanh',\n",
    "                       solver='lbfgs',\n",
    "                       max_iter=100,\n",
    "                       )\n",
    "model1.fit(X_train, y_train)\n",
    "predictions = model1.predict(X_test)\n",
    "print(\" ++++ Detailed classification report for the selected model ++++ \" )\n",
    "print(\"Algorithm %s \" % model1)\n",
    "print(\"This model was trained and tuned on the development set using CV.\")\n",
    "print(\"The following results are computed on the separate test set:\")\n",
    "\n",
    "predictions = model1.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "df_cm = pandas.DataFrame(cm, columns=numpy.unique(y_test), index = numpy.unique(y_test))\n",
    "sns.heatmap(df_cm, square=True, annot=True, fmt='d', cbar=False )\n",
    "pl.xlabel('predicted')\n",
    "pl.ylabel('true')\n",
    "pl.show()\n",
    "\n",
    "print('\\n clasification report:\\n', classification_report(y_test, predictions))\n",
    "print('\\n')        \n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd7a9de7-c596-483d-9b4d-d0de5472cc1e",
   "metadata": {},
   "source": [
    "The accuracy of prediction is all near the center numbers such as 5,6, or 7. There is little to no percision on the lower seen numbers\n",
    "such as 3,4,8, or 9. The accuracy is around .50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9625108-bda7-416d-a009-52e2d7210a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.67      0.07      0.13        27\n",
      "           5       0.47      0.55      0.51       264\n",
      "           6       0.55      0.64      0.59       471\n",
      "           7       0.53      0.35      0.42       175\n",
      "           8       0.25      0.03      0.05        38\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.52       980\n",
      "   macro avg       0.35      0.24      0.24       980\n",
      "weighted avg       0.51      0.52      0.50       980\n",
      "\n",
      "done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Comparison of DT model to scaled model\n",
    "\n",
    "scaled_DT = make_pipeline( MinMaxScaler(), DecisionTreeClassifier(criterion='gini', max_depth=8 ) )  \n",
    "scaled_DT.fit(X_train, y_train)\n",
    "print(\"Detailed classification report:\")\n",
    "print('\\n')\n",
    "y_true, y_pred = y_test, scaled_DT.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "643047b2-dda3-4b2a-9598-618f4f343030",
   "metadata": {},
   "source": [
    "The results are very similar as the MLP model, both models really struggle with the lesser known outputs such as 3,4,8,9, \n",
    "but the Pipelined DT model does have some accuracy at the 3 and 8 outputs compared to MLP model of a 0 percision for the respective numbers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
